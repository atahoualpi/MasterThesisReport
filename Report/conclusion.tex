\chapter{Conclusion}

A sound designing tool has been presented in this study, where two different synthesis algorithms are implemented. The goal is to achieve physics-based procedural audio in a virtual environment in the Unity\textsuperscript{\textregistered} game engine which can be manipulated through intuitive controls. 

A number of everyday objects which are separated into different ``sound areas'' are recorded by striking each one of them at these different surface location. 3D models of these objects are created, matching their shape and dimensions. By analyzing the recordings with \gls{DSP} audio algorithms, it is possible to extract the modal data necessary for the sound synthesis stage. This data is fed into the modal synthesis model which is driven by physics events from the game engine. This process transfers successfully the sound properties of the real world objects to their corresponding virtual ones but has some limitations. Further extension of the tool is possible by adding more types of objects while following the same procedure.

Three different kinds of contact sounds have been synthesized; impact sounds and continuous contact sounds, namely rolling and scratching. The tool's \gls{UI}, with high level adjustable parameters, enables the designers to customize the sounds according to their needs. A metallic object can be transformed into a wooden one just by adjusting a slider. In addition, having the original objects' sizes as reference, designers are able to scale the produced sound together with the object. Finally, the surface's roughness can be fine-tuned to match the desired sound of a rolling object.

Listening experiments performed to several individuals did not favor noticeably one synthesis method over the other. The methods presented better results for certain materials and \textit{vice versa}. However the filter-based method was proven to integrate better within an interactive scene thanks to its flexibility. Moreover, it was confirmed through user testing that sound variation along an object's surface is desirable and is preferred over just a single sound per object. Finally, the distinction of the different materials for a range of values of the \gls{Q} factor was identified well from the participants. Hence, the use of a one dimensional slider to shift from one material to another was justified.

Although the extraction of data from recordings offers computational efficiency, it is impossible to include the whole sound information without alterations. Thus, the synthesized sounds do not sound exactly like the references, but their source is highly recognizable. In addition, the tool used for striking the objects produces a sound as well, which interferes with the desired sound. Another aspect that can improve the recording process is to try to approximate as much as possible the system to a free vibration when holding the struck object in the air.

Physics-based procedural audio aims to increase realism and sense of presence in virtual worlds. Audio events match exactly with graphic events and complement one another, producing a compelling experience for the user.