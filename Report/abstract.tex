\chapter*{Abstract}

Audio that is consistent and in synchrony with the visual graphics in a game is of crucial importance. Prerecorded sounds lack the flexibility needed in a virtual environment. Procedural audio, on the other hand, generates highly dynamic audio that can handle unpredictable events, while solving the storage problem of portable devices. 

Sound interactions within a game consist of impact, rolling and scratching sounds. Two different ways of synthesizing these sounds are examined in this thesis, both deriving from modal synthesis. After extracting the modal data from example real world recordings, they are fed either into a number of damped oscillators, or a number of band-pass filters. To achieve sound variation, several different recordings are used, each one corresponding to a different area of the object.

Similar UI with Unity\textsuperscript{\textregistered}'s is implemented to achieve consistency. Sound designers are provided with high level parameters, which form a tool that generates physics-based procedural audio.

Based on perceptual tests performed, a single parameter is able to produce noticeable changes in material and also, sound variation along an object's surface is desirable and preferred over one single sound.
